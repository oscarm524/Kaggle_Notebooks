{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/oscarm524/ps-s3-ep22-eda-modeling-submission?scriptVersionId=142885575\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a id=\"table\"></a>\n<h1 style=\"background-color:lightgray;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;\">Table of Contents</h1>\n\n[1. Notebook Versions](#1)\n\n[2. Loading Libraries](#2)\n\n[3. Reading Data Files](#3)\n\n[4. Data Exploration](#4)\n\n[5. Baseline Modeling 1.0](#5)\n\n\n<a id=\"1\"></a>\n# <h1 style=\"background-color:lightgray;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;\">Notebook Versions</h1>\n\n- Version 1 (09/11/2023)\n    * EDA \n    \n    \n- Version 2 (09/12/2023)\n    * EDA updated\n    \n    \n- Version 3 (09/12/2023)\n    * EDA updated\n    \n    \n- Version 4 (09/13/2023)\n    * Baseline modeling 1.0 added\n    \n<a id=\"2\"></a>\n# <h1 style=\"background-color:lightgray;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;\">Loading Libraries</h1>    ","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd; pd.set_option('display.max_columns', 100)\nimport numpy as np\n\nfrom tqdm.notebook import tqdm\n\nimport re\n\nfrom functools import partial\nimport scipy as sp\nfrom scipy.stats import mode\n\nimport matplotlib.pyplot as plt; plt.style.use('ggplot')\nimport seaborn as sns\nimport plotly.express as px\n\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV, RepeatedStratifiedKFold\nfrom sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay, cohen_kappa_score, log_loss, f1_score\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.feature_selection import RFE, RFECV\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.calibration import CalibrationDisplay\nfrom sklearn.inspection import PartialDependenceDisplay\nfrom sklearn.linear_model import LogisticRegression\nfrom collections import Counter\nfrom sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:24:51.506432Z","iopub.execute_input":"2023-09-13T14:24:51.507163Z","iopub.status.idle":"2023-09-13T14:24:51.521001Z","shell.execute_reply.started":"2023-09-13T14:24:51.507124Z","shell.execute_reply":"2023-09-13T14:24:51.519753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n# <h1 style=\"background-color:lightgray;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;\">Reading Data Files</h1> ","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/playground-series-s3e22/train.csv')\ntest = pd.read_csv('../input/playground-series-s3e22/test.csv')\nsubmission = pd.read_csv('../input/playground-series-s3e22/sample_submission.csv')\noriginal = pd.read_csv('../input/horse-survival-dataset/horse.csv')\n\nprint('The dimension of the train dataset is:', train.shape)\nprint('The dimension of the test dataset is:', test.shape)\nprint('The dimension of the original train dataset is:', original.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:45:21.612514Z","iopub.execute_input":"2023-09-13T14:45:21.613044Z","iopub.status.idle":"2023-09-13T14:45:21.670137Z","shell.execute_reply.started":"2023-09-13T14:45:21.613Z","shell.execute_reply":"2023-09-13T14:45:21.668972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n# <h1 style=\"background-color:lightgray;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;\">Data Exploration</h1>\n\nFirst, we explore the competition dataset. We start by visualizing `outcome`, the variable of interest.","metadata":{}},{"cell_type":"code","source":"sns.countplot(data = train, x = 'outcome')\nplt.ylabel('Frequency');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T22:19:08.787352Z","iopub.execute_input":"2023-09-12T22:19:08.7878Z","iopub.status.idle":"2023-09-12T22:19:09.083725Z","shell.execute_reply.started":"2023-09-12T22:19:08.787765Z","shell.execute_reply":"2023-09-12T22:19:09.082326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above, the most frequent label is `lived`; on the other hand, `euthanized` is the least frequent label. Next, we explore relationships between the categorical features and `outcome`.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize = (25, 17))\n\ncmap = sns.diverging_palette(100, 7, s = 75, l = 40, n = 5, center = 'light', as_cmap = True)\n\nsns.heatmap(data = pd.crosstab(train['surgery'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[0, 0])\nsns.heatmap(data = pd.crosstab(train['age'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[0, 1])\nsns.heatmap(data = pd.crosstab(train['temp_of_extremities'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[1, 0])\nsns.heatmap(data = pd.crosstab(train['peripheral_pulse'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[1, 1]);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T22:19:11.015095Z","iopub.execute_input":"2023-09-12T22:19:11.015507Z","iopub.status.idle":"2023-09-12T22:19:12.906343Z","shell.execute_reply.started":"2023-09-12T22:19:11.015471Z","shell.execute_reply":"2023-09-12T22:19:12.905209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above heatmaps, these are some observations:\n\n- `young` horses are more likely to die.\n- horses with `temp_of_extremities = normal` are more likely to live.\n- horses with `peripheral_pulse = normal` are more likely to live.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize = (25, 17))\n\nsns.heatmap(data = pd.crosstab(train['mucous_membrane'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[0, 0])\nsns.heatmap(data = pd.crosstab(train['capillary_refill_time'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[0, 1])\nsns.heatmap(data = pd.crosstab(train['pain'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[1, 0])\nsns.heatmap(data = pd.crosstab(train['peristalsis'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[1, 1]);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T22:19:17.142611Z","iopub.execute_input":"2023-09-12T22:19:17.143001Z","iopub.status.idle":"2023-09-12T22:19:19.156001Z","shell.execute_reply.started":"2023-09-12T22:19:17.142969Z","shell.execute_reply":"2023-09-12T22:19:19.154871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above heatmaps, these are some observations:\n\n- horses with `mucous_membrane = normal_pink` are more likely to live.\n- Only two observations with `capillary_refill_time = 3`.\n- horses with `pain = mild_pain` are more likely to live.\n- Only one observation with `pain = slight`.\n- Only one observation with `peristalsis = distend_small`.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize = (25, 17))\n\nsns.heatmap(data = pd.crosstab(train['abdominal_distention'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[0, 0])\nsns.heatmap(data = pd.crosstab(train['nasogastric_tube'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[0, 1])\nsns.heatmap(data = pd.crosstab(train['nasogastric_reflux'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[1, 0])\nsns.heatmap(data = pd.crosstab(train['rectal_exam_feces'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[1, 1]);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T22:19:22.251742Z","iopub.execute_input":"2023-09-12T22:19:22.252166Z","iopub.status.idle":"2023-09-12T22:19:24.091066Z","shell.execute_reply.started":"2023-09-12T22:19:22.252131Z","shell.execute_reply":"2023-09-12T22:19:24.089998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above heatmaps, these are some observations:\n\n- horses with `abdominal_distention = slight` are more likely to live.\n- Only one observation with `nasogastric_reflux = slight`.\n- Only one observation with `rectal_exam_feces = serosanguious`.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize = (25, 17))\n\nsns.heatmap(data = pd.crosstab(train['abdomen'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[0, 0])\nsns.heatmap(data = pd.crosstab(train['abdomo_appearance'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[0, 1])\nsns.heatmap(data = pd.crosstab(train['surgical_lesion'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[1, 0])\nsns.heatmap(data = pd.crosstab(train['cp_data'], train['outcome']), annot = True, cmap = cmap, fmt = '.0f', ax = axes[1, 1]);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T22:19:27.875389Z","iopub.execute_input":"2023-09-12T22:19:27.875789Z","iopub.status.idle":"2023-09-12T22:19:29.777272Z","shell.execute_reply.started":"2023-09-12T22:19:27.87576Z","shell.execute_reply":"2023-09-12T22:19:29.776144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above heatmaps, these are some observations:\n\n- horses with `abdomo_appearance = clear` are more likely to live.\n- horses with `surgical_lesion = no` are more likely to live.\n\nNext, we explore potential relationships between the numeric input features and `outcome`.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize = (25, 17))\n\nsns.boxplot(ax = axes[0, 0], data = train, x = 'outcome', y = 'rectal_temp');\nsns.boxplot(ax = axes[0, 1], data = train, x = 'outcome', y = 'pulse');\nsns.boxplot(ax = axes[1, 0], data = train, x = 'outcome', y = 'respiratory_rate');\nsns.boxplot(ax = axes[1, 1], data = train, x = 'outcome', y = 'nasogastric_reflux_ph');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T22:19:33.521932Z","iopub.execute_input":"2023-09-12T22:19:33.523313Z","iopub.status.idle":"2023-09-12T22:19:34.448652Z","shell.execute_reply.started":"2023-09-12T22:19:33.523257Z","shell.execute_reply":"2023-09-12T22:19:34.447475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above boxplots, these are some observations:\n\n- `rectal_temp` distributions are similar across the three different labels of `outcome`.\n- The `pulse` of horses that lived, on average, is lower.\n- There is a slight downward trend in `respiratory_rate`, on average, from horses that died to horses that lived.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize = (25, 17))\n\nsns.boxplot(ax = axes[0, 0], data = train, x = 'outcome', y = 'packed_cell_volume');\nsns.boxplot(ax = axes[0, 1], data = train, x = 'outcome', y = 'total_protein');\nsns.boxplot(ax = axes[1, 0], data = train, x = 'outcome', y = 'abdomo_protein');\nsns.boxplot(ax = axes[1, 1], data = train, x = 'outcome', y = 'lesion_1');","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:19:38.760375Z","iopub.execute_input":"2023-09-12T22:19:38.760783Z","iopub.status.idle":"2023-09-12T22:19:39.667864Z","shell.execute_reply.started":"2023-09-12T22:19:38.760749Z","shell.execute_reply":"2023-09-12T22:19:39.666701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above boxplots, these are some observations:\n\n- On average, `euthanized` horses have a higher `picked_cell_volume`.\n- On average, `euthanized` horses have a higher `total_protein`.\n\nNext, we explore potential relationship among the input features via pair-plots.","metadata":{}},{"cell_type":"code","source":"sns.pairplot(data = train[['rectal_temp', 'respiratory_rate', 'nasogastric_reflux_ph', 'packed_cell_volume', 'total_protein', 'abdomo_protein', 'outcome']], hue = 'outcome', corner = True); ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T22:21:16.501553Z","iopub.execute_input":"2023-09-12T22:21:16.502035Z","iopub.status.idle":"2023-09-12T22:21:28.1021Z","shell.execute_reply.started":"2023-09-12T22:21:16.501998Z","shell.execute_reply":"2023-09-12T22:21:28.101008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above scatter-plots, these are some observations:\n\n- From the `total_protein` scatter-plots, it is clear that there are two groups of observations: `total_protein < 40` and `total_protein > 40`. Also notice that, when `total_protein > 45` most of the horses either `lived` or `euthanized`. This is could be a potential important feature to engineer.\n\n- From the `nasogastric_reflux_ph` scatter-plots, we observe when `nasogastric_reflux_ph > 2` there are more red dots; that is, it seems that when `nasogastric_reflux_ph > 2` the likelihood of dying increases. ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n# <h1 style=\"background-color:lightgray;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;\">Baseline Modeling 1.0</h1>\n\nIn this section, we start building some models (without much feature engineering nor HPO). First, we start by defining the input and targe variables as shown below.","metadata":{}},{"cell_type":"code","source":"X = pd.concat([pd.get_dummies(train[['surgery', 'age', 'temp_of_extremities', 'peripheral_pulse', 'abdominal_distention', 'abdomo_appearance', 'surgical_lesion']]), train[['pulse', 'respiratory_rate', 'total_protein', 'nasogastric_reflux_ph']]], axis = 1)\n\nY = train['outcome']\nY = Y.map({'died': 0, 'euthanized': 1, 'lived': 2})\n\ntest = pd.concat([pd.get_dummies(test[['surgery', 'age', 'temp_of_extremities', 'peripheral_pulse', 'abdominal_distention', 'abdomo_appearance', 'surgical_lesion']]), test[['pulse', 'respiratory_rate', 'total_protein', 'nasogastric_reflux_ph']]], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:23:15.206496Z","iopub.execute_input":"2023-09-13T14:23:15.206935Z","iopub.status.idle":"2023-09-13T14:23:15.254293Z","shell.execute_reply.started":"2023-09-13T14:23:15.206899Z","shell.execute_reply":"2023-09-13T14:23:15.252994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we run a simple 10-fold cross-validation routine to get an idea about model performance.","metadata":{}},{"cell_type":"code","source":"ens = list()\n\nsk = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 1, random_state = 42)\nfor i, (train_idx, test_idx) in enumerate(sk.split(X, Y)):\n\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n\n    print('----------------------------------------------------------')\n    \n    ###################\n    ## Random Forest ##\n    ###################\n    \n    RF_md = RandomForestClassifier(n_estimators = 500, \n                                   max_depth = 7,\n                                   min_samples_split = 15,\n                                   min_samples_leaf = 10).fit(X_train, Y_train)\n\n    RF_pred = RF_md.predict(X_test)\n    RF_pred_test = RF_md.predict(test)\n    RF_score = f1_score(Y_test, RF_pred, average = 'micro')\n\n    print('Fold', i, '==> RF oof F1 score is ==>', RF_score)\n\n    #################\n    ## Extra Trees ##\n    #################\n\n    ET_md = ExtraTreesClassifier(n_estimators = 500, \n                                 max_depth = 7,\n                                 min_samples_split = 15,\n                                 min_samples_leaf = 10).fit(X_train, Y_train)\n\n    ET_pred = ET_md.predict(X_test)\n    ET_pred_test = ET_md.predict(test)\n    ET_score = f1_score(Y_test, ET_pred, average = 'micro')\n\n    print('Fold', i, '==> ET oof F1 score is ==>', ET_score)\n\n    ######################\n    ## GradientBoosting ##\n    ######################\n\n    GB_md = GradientBoostingClassifier(n_estimators = 500, \n                                       learning_rate = 0.01,\n                                       max_depth = 7,\n                                       min_samples_split = 15,\n                                       min_samples_leaf = 10).fit(X_train, Y_train)\n\n    GB_pred = GB_md.predict(X_test)\n    GB_pred_test = GB_md.predict(test)\n    GB_score = f1_score(Y_test, GB_pred, average = 'micro')\n\n    print('Fold', i, '==> GB oof F1 score is ==>', GB_score)\n\n    ##########################\n    ## HistGradientBoosting ##\n    ##########################\n\n    hist_md = HistGradientBoostingClassifier(l2_regularization = 0.01,\n                                             early_stopping = False,\n                                             learning_rate = 0.01,\n                                             max_iter = 500,\n                                             max_depth = 7,\n                                             max_bins = 255,\n                                             min_samples_leaf = 5,\n                                             max_leaf_nodes = 5).fit(X_train, Y_train)\n    \n    hist_pred = hist_md.predict(X_test)\n    hist_pred_test = hist_md.predict(test)\n    hist_score = f1_score(Y_test, hist_pred, average = 'micro')\n\n    print('Fold', i, '==> Hist oof F1 score is ==>', hist_score)   \n\n    ##########\n    ## LGBM ##\n    ##########\n\n    LGBM_md = LGBMClassifier(objective = 'multiclass',\n                             n_estimators = 500,\n                             max_depth = 7,\n                             learning_rate = 0.01,\n                             num_leaves = 20,\n                             reg_alpha = 3,\n                             reg_lambda = 3,\n                             subsample = 0.7,\n                             colsample_bytree = 0.7).fit(X_train, Y_train)\n\n    lgb_pred = LGBM_md.predict(X_test)\n    lgb_pred_test = LGBM_md.predict(test)\n    lgb_score = f1_score(Y_test, lgb_pred, average = 'micro')\n\n    print('Fold', i, '==> LGBM oof F1 score is ==>', lgb_score)  \n\n    #########\n    ## XGB ##\n    #########\n\n    XGB_md = XGBClassifier(objective = 'multi:softprob',\n                           tree_method = 'hist',\n                           colsample_bytree = 0.7, \n                           gamma = 2, \n                           learning_rate = 0.01, \n                           max_depth = 7, \n                           min_child_weight = 10, \n                           n_estimators = 500, \n                           subsample = 0.7).fit(X_train, Y_train)\n\n    xgb_pred = XGB_md.predict(X_test)\n    xgb_pred_test = XGB_md.predict(test)\n    xgb_score = f1_score(Y_test, xgb_pred, average = 'micro')\n\n    print('Fold', i, '==> XGB oof F1 score is ==>', xgb_score)\n\n    ##############\n    ## CatBoost ##\n    ##############\n\n    Cat_md = CatBoostClassifier(loss_function = 'MultiClass',\n                                iterations = 500,\n                                learning_rate = 0.01,\n                                depth = 7,\n                                random_strength = 0.5,\n                                bagging_temperature = 0.7,\n                                border_count = 30,\n                                l2_leaf_reg = 5,\n                                verbose = False, \n                                task_type = 'CPU').fit(X_train, Y_train)\n\n    cat_pred = Cat_md.predict(X_test)\n    cat_pred_test = Cat_md.predict(test)\n    cat_score = f1_score(Y_test, cat_pred, average = 'micro')\n\n    print('Fold', i, '==> CatBoost oof F1 score is ==>', cat_score)\n\n    ###################\n    ## Mode Ensemble ##\n    ###################\n\n    md_preds = pd.concat([pd.Series(RF_pred.flatten()), \n                          pd.Series(ET_pred.flatten()), \n                          pd.Series(GB_pred.flatten()), \n                          pd.Series(hist_pred.flatten()), \n                          pd.Series(lgb_pred.flatten()), \n                          pd.Series(xgb_pred.flatten()),\n                          pd.Series(cat_pred.flatten())], axis = 1)\n    \n    md_preds_test = pd.concat([pd.Series(RF_pred_test.flatten()), \n                               pd.Series(ET_pred_test.flatten()), \n                               pd.Series(GB_pred_test.flatten()), \n                               pd.Series(hist_pred_test.flatten()), \n                               pd.Series(lgb_pred_test.flatten()), \n                               pd.Series(xgb_pred_test.flatten()),\n                               pd.Series(cat_pred_test.flatten())], axis = 1)\n\n    mode_ens = mode(md_preds, axis = 1, keepdims = True)[0]\n    mode_score = f1_score(Y_test, mode_ens, average = 'micro')\n    \n    mode_ens_test = mode(md_preds_test, axis = 1, keepdims = True)[0]\n    ens.append(mode_ens_test)\n    \n    print('Fold', i, '==> Mode Ensemble oof F1 score is ==>', mode_score)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:37:32.496018Z","iopub.execute_input":"2023-09-13T14:37:32.496414Z","iopub.status.idle":"2023-09-13T14:41:04.681159Z","shell.execute_reply.started":"2023-09-13T14:37:32.496385Z","shell.execute_reply":"2023-09-13T14:41:04.679418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we ensemble the predictions of the 10-folds via mode.","metadata":{}},{"cell_type":"code","source":"submission['outcome'] = mode(np.concatenate(ens, axis = 1), axis = 1, keepdims = True)[0]\nsubmission['outcome'] = submission['outcome'].map({0: 'died', 1: 'euthanized', 2: 'lived'})\nsubmission.to_csv('Baseline_Modeling_1.csv', index = False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:48:49.592268Z","iopub.execute_input":"2023-09-13T14:48:49.592685Z","iopub.status.idle":"2023-09-13T14:48:49.664553Z","shell.execute_reply.started":"2023-09-13T14:48:49.592652Z","shell.execute_reply":"2023-09-13T14:48:49.663531Z"},"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}